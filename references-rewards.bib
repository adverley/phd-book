
@inproceedings{Matas2018,
  title     = {Sim-to-Real Reinforcement Learning for Deformable Object Manipulation},
  author    = {Matas, Jan and James, Stephen and Davison, Andrew J.},
  booktitle = {Proceedings of The 2nd Conference on Robot Learning},
  pages     = {734--743},
  year      = {2018},
  editor    = {Billard, Aude and Dragan, Anca and Peters, Jan and Morimoto, Jun},
  volume    = {87},
  series    = {Proceedings of Machine Learning Research},
  address   = {},
  month     = {29--31 Oct},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v87/matas18a/matas18a.pdf},
  url       = {http://proceedings.mlr.press/v87/matas18a.html},
  abstract  = {We have seen much recent progress in rigid object manipulation, but interaction with deformable objects has notably lagged behind. Due to the large configuration space of deformable objects, solutions using traditional modelling approaches require significant engineering work. Perhaps then, bypassing the need for explicit modelling and instead learning the control in an end-to-end manner serves as a better approach? Despite the growing interest in the use of end-to-end robot learning approaches, only a small amount of work has focused on their applicability to deformable object manipulation. Moreover, due to the large amount of data needed to learn these end-to-end solutions, an emerging trend is to learn control policies in simulation and then transfer them over to the real world. To date, no work has explored whether it is possible to learn and transfer deformable object policies. We believe that if sim-to-real methods are to be employed further, then it should be possible to learn to interact with a wide variety of objects, and not only rigid objects. In this work, we use a combination of state-of-the-art deep reinforcement learning algorithms to solve the problem of manipulating deformable objects (specifically cloth). We evaluate our approach on three tasks—folding a towel up to a mark, folding a face towel diagonally, and draping a piece of cloth over a hanger. Our agents are fully trained in simulation with domain randomisation, and then successfully deployed in the real world without having seen any real deformable objects.}
}
@article{Janssens2018,
  author  = {Janssens, Olivier and Van de Walle, Rik and Loccufier, Mia and Van Hoecke, Sofie},
  journal = {IEEE/ASME Transactions on Mechatronics},
  title   = {Deep Learning for Infrared Thermal Image Based Machine Health Monitoring},
  year    = {2018},
  volume  = {23},
  number  = {1},
  pages   = {151-159},
  doi     = {10.1109/TMECH.2017.2722479}
}

@article{Lyu2019image,
  title     = {Image-based process monitoring using deep learning framework},
  author    = {Lyu, Yuting and Chen, Junghui and Song, Zhihuan},
  journal   = {Chemometrics and Intelligent Laboratory Systems},
  volume    = {189},
  pages     = {8--17},
  year      = {2019},
  publisher = {Elsevier}
}

@inproceedings{Sun2017data,
  title     = {Revisiting unreasonable effectiveness of data in deep learning era},
  author    = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {843--852},
  year      = {2017}
}
@article{Ge2013,
  author  = {Ge, Zhiqiang and Song, Zhihuan and Gao, Furong},
  title   = {Review of Recent Research on Data-Based Process Monitoring},
  journal = {Industrial \& Engineering Chemistry Research},
  volume  = {52},
  number  = {10},
  pages   = {3543-3562},
  year    = {2013},
  doi     = {10.1021/ie302069q},
  url     = { 
        https://doi.org/10.1021/ie302069q
    
},
  eprint  = { 
        https://doi.org/10.1021/ie302069q
    
}
}


@article{Malhotra2016,
  author  = {Malhotra, Pankaj and Tv, Vishnu and Ramakrishnan, Anusha and Anand, Gaurangi and Vig, Lovekesh and Agarwal, Puneet and Shroff, Gautam},
  year    = {2016},
  month   = {08},
  pages   = {},
  title   = {Multi-Sensor Prognostics using an Unsupervised Health Index based on LSTM Encoder-Decoder},
  journal = {1st SIGKDD Workshop on Machine Learning for Prognostics and Health Management}
}
@inproceedings{Finn2016,
  title     = {Guided cost learning: Deep inverse optimal control via policy optimization},
  author    = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle = {International Conference on Machine Learning},
  pages     = {49--58},
  year      = {2016}
}

@article{Doumanoglou2016,
  author   = {Doumanoglou, Andreas and Stria, Jan and Peleka, Georgia and Mariolis, Ioannis and Petrik, Vladimir and Kargakos, Andreas and Wagner, Libor and Hlav{\'a}{\v{c}}, V{\'a}clav and Kim, Tae-Kyun and Malassiotis, Sotiris},
  journal  = {IEEE Transactions on Robotics},
  title    = {Folding Clothes Autonomously: A Complete Pipeline},
  year     = {2016},
  volume   = {32},
  number   = {6},
  pages    = {1461-1478},
  keywords = {clothing;image colour analysis;image texture;manipulators;robot vision;service robots;clothes folding;dual-armed robot;machine vision;robotic manipulation;crumpled garments;color information;texture information;grasping point;hanging garment;polygonal models;T-shirts;towels;shorts;Object segmentation;Robots;Deformable objects;Image segmentation;Grasping;Pose estimation;Active vision;clothes;deformable objects;manipulation;perception;random forests;robotics},
  doi      = {10.1109/TRO.2016.2602376},
  issn     = {1552-3098},
  month    = {Dec}
}


@inproceedings{Maitin2010,
  author    = {J. {Maitin-Shepard} and M. {Cusumano-Towner} and J. {Lei} and P. {Abbeel}},
  booktitle = {2010 IEEE International Conference on Robotics and Automation},
  title     = {Cloth grasp point detection based on multiple-view geometric cues with application to robotic towel folding},
  year      = {2010},
  volume    = {},
  number    = {},
  pages     = {2308-2315},
  keywords  = {clothing;manipulators;mobile robots;object detection;robot vision;service robots;multiple-view geometric cues;robotic towel folding;vision-based grasp point detection algorithm;general-purpose two-armed mobile robotic platform;general purpose manipulators;Robotics and automation;Robot vision systems;Clothing;Collaborative work;Robustness;Manipulators;Machine learning algorithms;USA Councils;Detection algorithms;Mobile robots},
  doi       = {10.1109/ROBOT.2010.5509439},
  issn      = {1050-4729},
  month     = {May}
}



@inproceedings{Balaguer2011,
  author    = {B. {Balaguer} and S. {Carpin}},
  booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title     = {Combining imitation and reinforcement learning to fold deformable planar objects},
  year      = {2011},
  volume    = {},
  number    = {},
  pages     = {1405-1412},
  keywords  = {Learning;Humans;Training data;Manipulators;Deformable models;Training},
  doi       = {10.1109/IROS.2011.6094992},
  issn      = {2153-0866},
  month     = {Sep.}
}



@article{Miller2012,
  author   = {Stephen Miller and Jur van den Berg and Mario Fritz and Trevor Darrell and Ken Goldberg and Pieter Abbeel},
  title    = {A geometric approach to robotic laundry folding},
  journal  = {The International Journal of Robotics Research},
  volume   = {31},
  number   = {2},
  pages    = {249-267},
  year     = {2012},
  doi      = {10.1177/0278364911430417},
  url      = { 
        https://doi.org/10.1177/0278364911430417
    
},
  eprint   = { 
        https://doi.org/10.1177/0278364911430417
    
},
  abstract = { We consider the problem of autonomous robotic laundry folding, and propose a solution to the perception and manipulation challenges inherent to the task. At the core of our approach is a quasi-static cloth model which allows us to neglect the complex dynamics of cloth under significant parts of the state space, allowing us to reason instead in terms of simple geometry. We present an algorithm which, given a 2D cloth polygon and a desired sequence of folds, outputs a motion plan for executing the corresponding manipulations, deemed g-folds, on a minimal number of robot grippers. We define parametrized fold sequences for four clothing categories: towels, pants, short-sleeved shirts, and long-sleeved shirts, each represented as polygons. We then devise a model-based optimization approach for visually inferring the class and pose of a spread-out or folded clothing article from a single image, such that the resulting polygon provides a parse suitable for these folding primitives. We test the manipulation and perception tasks individually, and combine them to implement an autonomous folding system on the Willow Garage PR2. This enables the PR2 to identify a clothing article spread out on a table, execute the computed folding sequence, and visually track its progress over successive folds. }
}

@article{Bellman1959,
  author  = {Bellman, Richard and Kalaba, Robert},
  journal = {IRE Transactions on Automatic Control},
  title   = {On adaptive control processes},
  year    = {1959},
  volume  = {4},
  number  = {2},
  pages   = {1-9}
}

@article{Leys2013,
  title    = {Detecting outliers: Do not use standard deviation around the mean, use absolute deviation around the median},
  journal  = {Journal of Experimental Social Psychology},
  volume   = {49},
  number   = {4},
  pages    = {764 - 766},
  year     = {2013},
  issn     = {0022-1031},
  doi      = {https://doi.org/10.1016/j.jesp.2013.03.013},
  url      = {http://www.sciencedirect.com/science/article/pii/S0022103113000668},
  author   = {Christophe Leys and Christophe Ley and Olivier Klein and Philippe Bernard and Laurent Licata},
  keywords = {Median absolute deviation, Outlier, MAD},
  abstract = {A survey revealed that researchers still seem to encounter difficulties to cope with outliers. Detecting outliers by determining an interval spanning over the mean plus/minus three standard deviations remains a common practice. However, since both the mean and the standard deviation are particularly sensitive to outliers, this method is problematic. We highlight the disadvantages of this method and present the median absolute deviation, an alternative and more robust measure of dispersion that is easy to implement. We also explain the procedures for calculating this indicator in SPSS and R software.}
}

@article{UMAP,
  author        = {McInnes, Leland and Healy, John and Melville, James},
  title         = {{UMAP: Uniform Manifold Approximation
     and Projection for Dimension Reduction}},
  journal       = {ArXiv e-prints},
  archiveprefix = {arXiv},
  eprint        = {1802.03426},
  primaryclass  = {stat.ML},
  keywords      = {Statistics - Machine Learning,
                 Computer Science - Computational Geometry,
                 Computer Science - Learning},
  year          = 2018,
  month         = feb
}

@article{Argall2009,
  title     = {A survey of robot learning from demonstration},
  author    = {Argall, Brenna D and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
  journal   = {Robotics and autonomous systems},
  volume    = {57},
  number    = {5},
  pages     = {469--483},
  year      = {2009},
  publisher = {Elsevier}
}

@article{Nehavic2002,
  title     = {The correspondence problem},
  author    = {Nehaniv, Chrystopher L and Dautenhahn, Kerstin and others},
  journal   = {Imitation in animals and artifacts},
  volume    = {41},
  year      = {2002},
  publisher = {MIT press Cambridge, MA}
}


@article{Verleysen2020-dataset,
  abstract  = {General-purpose clothes-folding robots do not yet exist owing to the deformable nature of textiles, making it hard to engineer manipulation pipelines or learn this task. In order to accelerate research for the learning of the robotic clothes-folding task, we introduce a video dataset of human folding demonstrations. In total, we provide 8.5 hours of demonstrations from multiple perspectives leading to 1,000 folding samples of different types of textiles. The demonstrations are recorded in multiple public places, in different conditions with a diverse set of people. Our dataset consists of anonymized RGB images, depth frames, skeleton keypoint trajectories, and object labels. In this article, we describe our recording setup, the data format, and utility scripts, which can be accessed at https://adverley.github.io/folding-demonstrations},
  articleno = {027836492094040},
  author    = {Verleysen, Andreas and Biondina, Matthijs and wyffels, Francis},
  issn      = {0278-3649},
  journal   = {The International Journal of Robotics Research},
  keywords  = {Deformable objects,robotic manipulation,clothing,learning from demonstration,crowdsourcing},
  language  = {eng},
  title     = {Video dataset of human demonstrations of folding clothing for robotic folding},
  url       = {http://dx.doi.org/10.1177/0278364920940408},
  year      = {2020}
}

@article{Verleysen2020-folding,
  abstract  = {Deformable objects such as ropes, wires, and clothing are omnipresent in society and industry but are little researched in robotics research. This is due to the infinite amount of possible state configurations caused by the deformations of the deformable object. Engineered approaches try to cope with this by implementing highly complex operations in order to estimate the state of the deformable object. This complexity can be circumvented by utilizing learning-based approaches, such as reinforcement learning, which can deal with the intrinsic high-dimensional state space of deformable objects. However, the reward function in reinforcement learning needs to measure the state configuration of the highly deformable object. Vision-based reward functions are difficult to implement, given the high dimensionality of the state and complex dynamic behavior. In this work, we propose the consideration of concepts beyond vision and incorporate other modalities which can be extracted from deformable objects. By integrating tactile sensor cells into a textile piece, proprioceptive capabilities are gained that are valuable as they provide a reward function to a reinforcement learning agent. We demonstrate on a low-cost dual robotic arm setup that a physical agent can learn on a single CPU core to fold a rectangular patch of textile in the real world based on a learned reward function from tactile information.},
  articleno = {4088},
  author    = {Verleysen, Andreas and Holvoet, Thomas and Proesmans, Remko and Den Haese, Cedric and wyffels, Francis},
  issn      = {2076-3417},
  journal   = {APPLIED SCIENCES-BASEL},
  keywords  = {deformable object manipulation,smart textile,low-cost,reinforcement learning},
  language  = {eng},
  number    = {12},
  pages     = {10},
  title     = {Simpler learning of robotic manipulation of clothing by utilizing DIY smart textile technology},
  url       = {http://dx.doi.org/10.3390/app10124088},
  volume    = {10},
  year      = {2020}
}

@inproceedings{DenseNet2017,
  author    = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Densely Connected Convolutional Networks},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {2261-2269},
  doi       = {10.1109/CVPR.2017.243}
}


@article{Billard2019,
  title     = {Trends and challenges in robot manipulation},
  author    = {Billard, Aude and Kragic, Danica},
  doi       = {10.1126/science.aat8414},
  journal   = {Science},
  volume    = {364},
  number    = {6446},
  pages     = {eaat8414},
  year      = {2019},
  publisher = {American Association for the Advancement of Science}
}
@inproceedings{Ng1999,
  title     = {Policy invariance under reward transformations: Theory and application to reward shaping},
  author    = {Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle = {ICML},
  volume    = {99},
  pages     = {278--287},
  year      = {1999}
}

@inproceedings{Ng2000,
  title     = {Algorithms for inverse reinforcement learning.},
  author    = {Ng, Andrew Y and Russell, Stuart J and others},
  booktitle = {Icml},
  volume    = {1},
  pages     = {2},
  year      = {2000}
}

@article{Yin2015,
  author  = {Yin, Shen and Ding, Steven X. and Xie, Xiaochen and Luo, Hao},
  journal = {IEEE Transactions on Industrial Electronics},
  title   = {A Review on Basic Data-Driven Approaches for Industrial Process Monitoring},
  year    = {2014},
  volume  = {61},
  number  = {11},
  pages   = {6418-6428},
  doi     = {10.1109/TIE.2014.2301773}
}

@inproceedings{Fu2018,
  title     = {Learning Robust Rewards with Adverserial Inverse Reinforcement Learning},
  author    = {Fu, Justin and Luo, Katie and Levine, Sergey},
  booktitle = {International Conference on Learning Representations},
  year      = {2018}
}

@article{Kompella2017,
  title     = {Continual curiosity-driven skill acquisition from high-dimensional video inputs for humanoid robots},
  author    = {Kompella, Varun Raj and Stollenga, Marijn and Luciw, Matthew and Schmidhuber, Juergen},
  journal   = {Artificial Intelligence},
  volume    = {247},
  pages     = {313--335},
  year      = {2017},
  publisher = {Elsevier}
}

@article{Ramirez2017,
  title   = {Transferring skills to humanoid robots by extracting semantic representations from observations of human activities},
  journal = {Artificial Intelligence},
  volume  = {247},
  pages   = {95 - 118},
  year    = {2017},
  note    = {Special Issue on AI and Robotics},
  issn    = {0004-3702},
  doi     = {https://doi.org/10.1016/j.artint.2015.08.009},
  url     = {http://www.sciencedirect.com/science/article/pii/S0004370215001320},
  author  = {Karinne Ramirez-Amaro and Michael Beetz and Gordon Cheng}
}

@inproceedings{Ho2016,
  title     = {Generative adversarial imitation learning},
  author    = {Ho, Jonathan and Ermon, Stefano},
  booktitle = {Advances in neural information processing systems},
  pages     = {4565--4573},
  year      = {2016}
}

@inproceedings{Ross2011,
  title     = {A reduction of imitation learning and structured prediction to no-regret online learning},
  author    = {Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle = {Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages     = {627--635},
  year      = {2011}
}

@book{Rabiner1993,
  author    = {Rabiner, Lawrence and Juang, Biing-Hwang},
  title     = {Fundamentals of Speech Recognition},
  year      = {1993},
  isbn      = {0130151572},
  publisher = {Prentice-Hall, Inc.},
  address   = {USA}
}

@article{Lipton2018,
  author     = {Lipton, Zachary C.},
  title      = {The Mythos of Model Interpretability},
  year       = {2018},
  issue_date = {May-June 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {16},
  number     = {3},
  issn       = {1542-7730},
  url        = {https://doi.org/10.1145/3236386.3241340},
  doi        = {10.1145/3236386.3241340},
  journal    = {Queue},
  month      = jun,
  pages      = {31–57},
  numpages   = {27}
}

@inproceedings{Misra2016,
  title     = {{Shuffle and Learn: Unsupervised Learning using Temporal Order Verification}},
  author    = {Misra, Ishan and Zitnick, C. Lawrence and Hebert, Martial},
  booktitle = {ECCV},
  year      = {2016}
}

@inproceedings{Fernando2017,
  title     = {Self-supervised video representation learning with odd-one-out networks},
  author    = {Fernando, Basura and Bilen, Hakan and Gavves, Efstratios and Gould, Stephen},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {3636--3645},
  year      = {2017}
}



@inproceedings{Lee2017,
  author    = {Lee, Hsin-Ying and Huang, Jia-Bin and Singh, Maneesh Kumar and Yang, Ming-Hsuan},
  title     = {Unsupervised Representation Learning by Sorting Sequence},
  booktitle = {IEEE International Conference on Computer Vision},
  year      = {2017}
}

@article{Sermanet2017Rewards,
  author  = {Pierre Sermanet and
               Kelvin Xu and
               Sergey Levine},
  title   = {Unsupervised Perceptual Rewards for Imitation Learning},
  journal = {Proceedings of Robotics: Science and Systems (RSS)},
  year    = {2017},
  url     = {http://arxiv.org/abs/1612.06699},
  biburl  = {https://github.com/sermanet/home/blob/master/docs/bib/Sermanet2017Rewards.bib}
}

@inproceedings{Sermanet2017TCN,
  title        = {Time-contrastive networks: Self-supervised learning from video},
  author       = {Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey and Brain, Google},
  booktitle    = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages        = {1134--1141},
  year         = {2018},
  organization = {IEEE}
}



             @inproceedings{Dwibedi2018mfTCN,
  author       = {Dwibedi, Debidatta and Tompson, Jonathan and Lynch, Corey and Sermanet, Pierre},
  title        = {Learning Actionable Representations from Visual Observations},
  booktitle    = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages        = {1577--1584},
  year         = {2018},
  organization = {IEEE},
  url          = {https://arxiv.org/abs/1808.00928}
}
         
                 @inproceedings{Dwibedi2019cycle,
  author    = {Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
  title     = {Temporal Cycle-Consistency Learning},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2019}
}
				
				@article{Srinivas2020CURL,
  title   = {CURL: Contrastive Unsupervised Representations for Reinforcement Learning},
  author  = {Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  note    = {arXiv:2003.06417},
  journal = {Proceedings of the 37th International Conference on Machine 
  Learning, Vienna, Austria, PMLR 119},
  year    = {2020}
}

@article{Folgado2018,
  title    = {Time Alignment Measurement for Time Series},
  journal  = {Pattern Recognition},
  volume   = {81},
  pages    = {268 - 279},
  year     = {2018},
  issn     = {0031-3203},
  doi      = {https://doi.org/10.1016/j.patcog.2018.04.003},
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320318301286},
  author   = {Duarte Folgado and Marília Barandas and Ricardo Matias and Rodrigo Martins and Miguel Carvalho and Hugo Gamboa},
  keywords = {Time series, Time warping, Similarity, Distance, Signal alignment},
  abstract = {When a comparison between time series is required, measurement functions provide meaningful scores to characterize similarity between sequences. Quite often, time series appear warped in time, i.e, although they may exhibit amplitude and shape similarity, they appear dephased in time. The most common algorithm to overcome this challenge is the Dynamic Time Warping, which aligns each sequence prior establishing distance measurements. However, Dynamic Time Warping takes only into account amplitude similarity. A distance which characterizes the degree of time warping between two sequences can deliver new insights for applications where the timing factor is essential, such well-defined movements during sports or rehabilitation exercises. We propose a novel measurement called Time Alignment Measurement, which delivers similarity information on the temporal domain. We demonstrate the potential of our approach in measuring performance of time series alignment methodologies and in the characterization of synthetic and real time series data acquired during human movement.}
}

@article{Machado2015,
  title    = {Human activity data discovery from triaxial accelerometer sensor: Non-supervised learning sensitivity to feature extraction parametrization},
  journal  = {Information Processing \& Management},
  volume   = {51},
  number   = {2},
  pages    = {204 - 214},
  year     = {2015},
  issn     = {0306-4573},
  doi      = {https://doi.org/10.1016/j.ipm.2014.07.008},
  url      = {http://www.sciencedirect.com/science/article/pii/S0306457314000685},
  author   = {Inês P. Machado and A. {Luísa Gomes} and Hugo Gamboa and Vítor Paixão and Rui M. Costa},
  keywords = {Human activity recognition, Interactive knowledge discovery, Feature extraction, Dimensionality reduction, Clustering algorithms}
}
@article{Zhao2019,
  title    = {Deep learning and its applications to machine health monitoring},
  journal  = {Mechanical Systems and Signal Processing},
  volume   = {115},
  pages    = {213-237},
  year     = {2019},
  issn     = {0888-3270},
  doi      = {https://doi.org/10.1016/j.ymssp.2018.05.050},
  url      = {https://www.sciencedirect.com/science/article/pii/S0888327018303108},
  author   = {Rui Zhao and Ruqiang Yan and Zhenghua Chen and Kezhi Mao and Peng Wang and Robert X. Gao},
  keywords = {Deep learning, Machine health monitoring, Big data},
  abstract = {Since 2006, deep learning (DL) has become a rapidly growing research direction, redefining state-of-the-art performances in a wide range of areas such as object recognition, image segmentation, speech recognition and machine translation. In modern manufacturing systems, data-driven machine health monitoring is gaining in popularity due to the widespread deployment of low-cost sensors and their connection to the Internet. Meanwhile, deep learning provides useful tools for processing and analyzing these big machinery data. The main purpose of this paper is to review and summarize the emerging research work of deep learning on machine health monitoring. After the brief introduction of deep learning techniques, the applications of deep learning in machine health monitoring systems are reviewed mainly from the following aspects: Auto-encoder (AE) and its variants, Restricted Boltzmann Machines and its variants including Deep Belief Network (DBN) and Deep Boltzmann Machines (DBM), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). In addition, an experimental study on the performances of these approaches has been conducted, in which the data and code have been online. Finally, some new trends of DL-based machine health monitoring methods are discussed.}
}

@article{Pham2005,
  title     = {Machine-learning techniques and their applications in manufacturing},
  author    = {Pham, Duc T and Afify, Ashraf A},
  journal   = {Proceedings of the Institution of Mechanical Engineers, Part B: Journal of Engineering Manufacture},
  volume    = {219},
  number    = {5},
  pages     = {395--412},
  year      = {2005},
  publisher = {Sage Publications Sage UK: London, England}
}
@book{Wang2012,
  title     = {Data mining and knowledge discovery for process monitoring and control},
  author    = {Wang, Xue Z},
  year      = {2012},
  publisher = {Springer Science \& Business Media}
}

@inproceedings{Li2004,
  author    = {Haisheng Li and Xuefeng Zhu},
  booktitle = {Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788)},
  title     = {Application of support vector machine method in prediction of Kappa number of kraft pulping process},
  year      = {2004},
  volume    = {4},
  number    = {},
  pages     = {3325-3330 Vol.4},
  doi       = {10.1109/WCICA.2004.1343151}
}

@article{Kang2016,
  title    = {Semi-supervised support vector regression based on self-training with label uncertainty: An application to virtual metrology in semiconductor manufacturing},
  journal  = {Expert Systems with Applications},
  volume   = {51},
  pages    = {85-106},
  year     = {2016},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2015.12.027},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417415008295},
  author   = {Pilsung Kang and Dongil Kim and Sungzoon Cho},
  keywords = {Semi-supervised learning, Support vector regression, Probabilistic local reconstruction, Data generation, Virtual metrology, Semiconductor manufacturing},
  abstract = {Dataset size continues to increase and data are being collected from numerous applications. Because collecting labeled data is expensive and time consuming, the amount of unlabeled data is increasing. Semi-supervised learning (SSL) has been proposed to improve conventional supervised learning methods by training from both unlabeled and labeled data. In contrast to classification problems, the estimation of labels for unlabeled data presents added uncertainty for regression problems. In this paper, a semi-supervised support vector regression (SS-SVR) method based on self-training is proposed. The proposed method addresses the uncertainty of the estimated labels for unlabeled data. To measure labeling uncertainty, the label distribution of the unlabeled data is estimated with two probabilistic local reconstruction (PLR) models. Then, the training data are generated by oversampling from the unlabeled data and their estimated label distribution. The sampling rate is different based on uncertainty. Finally, expected margin-based pattern selection (EMPS) is employed to reduce training complexity. We verify the proposed method with 30 regression datasets and a real-world problem: virtual metrology (VM) in semiconductor manufacturing. The experiment results show that the proposed method improves the accuracy by 8 compared with conventional supervised SVR, and the training time for the proposed method is 20 shorter than that of the benchmark methods.}
}

@article{Wuest2016,
  title     = {Machine learning in manufacturing: advantages, challenges, and applications},
  author    = {Wuest, Thorsten and Weimer, Daniel and Irgens, Christopher and Thoben, Klaus-Dieter},
  journal   = {Production \& Manufacturing Research},
  volume    = {4},
  number    = {1},
  pages     = {23--45},
  year      = {2016},
  publisher = {Taylor \& Francis}
}

@article{Lei2016,
  author  = {Lei, Yaguo and Jia, Feng and Lin, Jing and Xing, Saibo and Ding, Steven X.},
  journal = {IEEE Transactions on Industrial Electronics},
  title   = {An Intelligent Fault Diagnosis Method Using Unsupervised Feature Learning Towards Mechanical Big Data},
  year    = {2016},
  volume  = {63},
  number  = {5},
  pages   = {3137-3147},
  doi     = {10.1109/TIE.2016.2519325}
}

@article{Wen2018,
  author  = {Wen, Long and Li, Xinyu and Gao, Liang and Zhang, Yuyan},
  journal = {IEEE Transactions on Industrial Electronics},
  title   = {A New Convolutional Neural Network-Based Data-Driven Fault Diagnosis Method},
  year    = {2018},
  volume  = {65},
  number  = {7},
  pages   = {5990-5998},
  doi     = {10.1109/TIE.2017.2774777}
}

@article{Chen2020,
  title    = {Robust Bayesian networks for low-quality data modeling and process monitoring applications},
  journal  = {Control Engineering Practice},
  volume   = {97},
  pages    = {104344},
  year     = {2020},
  issn     = {0967-0661},
  doi      = {https://doi.org/10.1016/j.conengprac.2020.104344},
  url      = {https://www.sciencedirect.com/science/article/pii/S0967066120300289},
  author   = {Guangjie Chen and Zhiqiang Ge},
  keywords = {Robust Bayesian network, Data quality feature, Process monitoring, Fault diagnosis},
  abstract = {In this paper, a novel robust Bayesian network is proposed for process modeling with low-quality data. Since unreliable data can cause model parameters to deviate from the real distributions and make network structures unable to characterize the true causalities, data quality feature is utilized to improve the process modeling and monitoring performance. With a predetermined trustworthy center, the data quality measurement results can be evaluated through an exponential function with Mahalanobis distances. The conventional Bayesian network learning algorithms including structure learning and parameter learning are modified by the quality feature in a weighting form, intending to extract useful information and make a reasonable model. The effectiveness of the proposed method is demonstrated through TE benchmark process and a real industrial process.}
}

@article{Myers1980,
  title     = {Performance tradeoffs in dynamic time warping algorithms for isolated word recognition},
  author    = {Myers, Cory and Rabiner, Lawrence and Rosenberg, Aaron},
  journal   = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  volume    = {28},
  number    = {6},
  pages     = {623--635},
  year      = {1980},
  publisher = {IEEE}
}

@article{Seyler2015path,
  title     = {Path similarity analysis: a method for quantifying macromolecular pathways},
  author    = {Seyler, Sean L and Kumar, Avishek and Thorpe, Michael F and Beckstein, Oliver},
  journal   = {PLoS Comput Biol},
  volume    = {11},
  number    = {10},
  pages     = {e1004568},
  year      = {2015},
  publisher = {Public Library of Science}
}


@inproceedings{FaceNet,
  title     = {Facenet: A unified embedding for face recognition and clustering},
  author    = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {815--823},
  year      = {2015}
}


@inproceedings{Pathak2016,
  title     = {Context encoders: Feature learning by inpainting},
  author    = {Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {2536--2544},
  year      = {2016}
}

@inproceedings{Doersch2015,
  title     = {Unsupervised visual representation learning by context prediction},
  author    = {Doersch, Carl and Gupta, Abhinav and Efros, Alexei A},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {1422--1430},
  year      = {2015}
}


@inproceedings{Zhang2016Color,
  title        = {Colorful image colorization},
  author       = {Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle    = {European conference on computer vision},
  pages        = {649--666},
  year         = {2016},
  organization = {Springer}
}
@article{Devlin2018,
  title   = {Bert: Pre-training of deep bidirectional transformers for language understanding},
  author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal = {arXiv preprint arXiv:1810.04805},
  year    = {2018}
}

@article{Singh2019,
  title   = {End-to-end robotic reinforcement learning without reward engineering},
  author  = {Singh, Avi and Yang, Larry and Hartikainen, Kristian and Finn, Chelsea and Levine, Sergey},
  journal = {arXiv preprint arXiv:1904.07854},
  year    = {2019}
}

@inproceedings{Hartikainen2019,
  title     = {Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill Discovery},
  author    = {Hartikainen, Kristian and Geng, Xinyang and Haarnoja, Tuomas and Levine, Sergey},
  booktitle = {International Conference on Learning Representations},
  year      = {2019}
}

@article{Nair2018time,
  title   = {Time reversal as self-supervision},
  author  = {Nair, Suraj and Babaeizadeh, Mohammad and Finn, Chelsea and Levine, Sergey and Kumar, Vikash},
  journal = {arXiv preprint arXiv:1810.01128},
  year    = {2018}
}

@inproceedings{Nair2018visual,
  title     = {Visual reinforcement learning with imagined goals},
  author    = {Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {9191--9200},
  year      = {2018}
}

@article{Gallese2004,
  title     = {A unifying view of the basis of social cognition},
  author    = {Gallese, Vittorio and Keysers, Christian and Rizzolatti, Giacomo},
  journal   = {Trends in cognitive sciences},
  volume    = {8},
  number    = {9},
  pages     = {396--403},
  year      = {2004},
  publisher = {Elsevier}
}

@article{Tormene2009,
  title    = {Matching incomplete time series with dynamic time warping: an algorithm and an application to post-stroke rehabilitation},
  journal  = {Artificial Intelligence in Medicine},
  volume   = {45},
  number   = {1},
  pages    = {11 - 34},
  year     = {2009},
  issn     = {0933-3657},
  doi      = {https://doi.org/10.1016/j.artmed.2008.11.007},
  url      = {http://www.sciencedirect.com/science/article/pii/S0933365708001772},
  author   = {Paolo Tormene and Toni Giorgino and Silvana Quaglini and Mario Stefanelli},
  keywords = {Dynamic programming, Timeseries classification, Nearest neighbour, Motor rehabilitation, Real-time feedback, Post-stroke, Dynamic time warping, Subsequence matching, Wearable sensors}
}

@article{Levine2016,
  title     = {End-to-end training of deep visuomotor policies},
  author    = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal   = {The Journal of Machine Learning Research},
  volume    = {17},
  number    = {1},
  pages     = {1334--1373},
  year      = {2016},
  publisher = {JMLR. org}
}

@article{VGG16,
  title   = {Very deep convolutional networks for large-scale image recognition},
  author  = {Simonyan, Karen and Zisserman, Andrew},
  journal = {arXiv preprint arXiv:1409.1556},
  year    = {2014}
}

@inproceedings{ImageNet,
  author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  title     = {{ImageNet: A Large-Scale Hierarchical Image Database}},
  booktitle = {CVPR09},
  year      = {2009},
  bibsource = {http://www.image-net.org/papers/imagenet_cvpr09.bib}
}
        
@article{BrassHeyes2005,
  author  = {Brass, Marcel and Heyes, Cecilia},
  year    = {2005},
  month   = {11},
  pages   = {489-95},
  title   = {Imitation: Is cognitive neuroscience solving the correspondence problem?},
  volume  = {9},
  journal = {Trends in cognitive sciences},
  doi     = {10.1016/j.tics.2005.08.007}
}

 @inproceedings{Kuzmanic2007,
  author    = {Kuzmanic, Ana and Zanchi, Vlasta},
  booktitle = {EUROCON 2007 - The International Conference on "Computer as a Tool"},
  title     = {Hand shape classification using DTW and LCSS as similarity measures for vision-based gesture recognition system},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {264-269},
  doi       = {10.1109/EURCON.2007.4400350}
}

@inproceedings{Niennattrakul2007,
  author    = {Niennattrakul, Vit and Ratanamahatana, Chotirat Ann},
  booktitle = {2007 International Conference on Multimedia and Ubiquitous Engineering (MUE'07)},
  title     = {On Clustering Multimedia Time Series Data Using K-Means and Dynamic Time Warping},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {733-738},
  doi       = {10.1109/MUE.2007.165}
}


@article{Foresti2004,
  author   = {Foresti, Gian Luca and Pellegrino, Felice Andrea},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  title    = {Automatic visual recognition of deformable objects for grasping and manipulation},
  year     = {2004},
  volume   = {34},
  number   = {3},
  pages    = {325-333},
  keywords = {self-organising feature maps;image segmentation;image texture;object recognition;image recognition;feature extraction;image colour analysis;automatic visual recognition;deformable objects;vision-based system;self-organized neural network;color image segmentation;image texture information;object recognition;points extraction;morphological analysis;object grasping;object manipulation;Deformable models;Data mining;Robot vision systems;Object recognition;Computer vision;Robotics and automation;Principal component analysis;Neural networks;Image segmentation;Color},
  doi      = {10.1109/TSMCC.2003.819701},
  issn     = {1094-6977},
  month    = {Aug}
}

@article{Ferreira2015,
  title    = {Reinforcement-learning based dialogue system for human–robot interactions with socially-inspired rewards},
  journal  = {Computer Speech \& Language},
  volume   = {34},
  number   = {1},
  pages    = {256 - 274},
  year     = {2015},
  issn     = {0885-2308},
  doi      = {https://doi.org/10.1016/j.csl.2015.03.007},
  url      = {http://www.sciencedirect.com/science/article/pii/S0885230815000364},
  author   = {Emmanuel Ferreira and Fabrice Lefèvre},
  keywords = {Human–robot interaction, POMDP-based dialogue management, Reinforcement learning, Reward shaping},
  abstract = {This paper investigates some conditions under which polarized user appraisals gathered throughout the course of a vocal interaction between a machine and a human can be integrated in a reinforcement learning-based dialogue manager. More specifically, we discuss how this information can be cast into socially-inspired rewards for speeding up the policy optimisation for both efficient task completion and user adaptation in an online learning setting. For this purpose a potential-based reward shaping method is combined with a sample efficient reinforcement learning algorithm to offer a principled framework to cope with these potentially noisy interim rewards. The proposed scheme will greatly facilitate the system's development by allowing the designer to teach his system through explicit positive/negative feedbacks given as hints about task progress, in the early stage of training. At a later stage, the approach will be used as a way to ease the adaptation of the dialogue policy to specific user profiles. Experiments carried out using a state-of-the-art goal-oriented dialogue management framework, the Hidden Information State (HIS), support our claims in two configurations: firstly, with a user simulator in the tourist information domain (and thus simulated appraisals), and secondly, in the context of man–robot dialogue with real user trials.}
}

@article{Wu2020,
  author  = {Z. {Wu} and L. {Sun} and W. {Zhan} and C. {Yang} and M. {Tomizuka}},
  journal = {IEEE Robotics and Automation Letters},
  title   = {Efficient Sampling-Based Maximum Entropy Inverse Reinforcement Learning With Application to Autonomous Driving},
  year    = {2020},
  volume  = {5},
  number  = {4},
  pages   = {5355-5362},
  doi     = {10.1109/LRA.2020.3005126}
}
