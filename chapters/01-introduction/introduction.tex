% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode

\providecommand{\home}{../..}
\documentclass[\home/main.tex]{subfiles}

\begin{document}


% Dit hoort volgens mij eerder thuis in introductie:
%For example, a recent cloth folding pipeline by~\citeauthor{Doumanoglou2016} starts with a visual perception to detect candidate grasp points. These grasp points are then given to a planning module to move the robot end-effector to the desired position and orientation. This divide-and-conquer methodology leads to a loss of information between the different stages, resulting in the accumulation of errors. \Citeauthor{Doumanoglou2016} report difficulties when folding towels because the perception system labels them as shirts. These individual components are built in a laboratory environment with certain assumptions which are likely to be violated in an unstructured, complex environment. Inaccurate sensor readings together with deformation of the robotâ€™s links also deteriorate the accuracy of these systems. In contrast, modern deep learning approaches try to achieve the same outcome in an end-to-end fashion. This is done by 

\chapter{introduction}\label{ch:introduction}


\section{Robotic laundry}
Structuur:
\begin{itemize}
    \item Droom van robot automatisatie
    \item Robotic laundry, een voorbeeld van household taak maar ook relevant voor Vlaamse industrie en breder: vervormbare objecten
    \item Traditionele robotic pipelines: hoe + waar ze falen
    \item Moderne robotic pipelines: wat ze oplossen maar waar we nog tekort schieten (single focus op rigide objecten, grote datasets of veel exp nodig en reward hacking).
    \item Insert figure~\ref{fig:intro_end2end} maar hermaak met eigen beelden!
\end{itemize}

Process of doing robotic laundry is visualized in Figure~\ref{fig:intro_robotic_laundry}.
\input{\home/chapters/01-introduction/figures/robotic-laundry-flow.tex}


\begin{figure}
    \includegraphics[width=\linewidth]{\home/chapters/01-introduction/figures/end2end-mockup}
    \caption{\textbf{Standard robotic control pipelines versus end-to-end architectures.} The diagram on the top shows how an image is processed to manually tuned features in order to do state estimation. This is then used downstream for trajectory planning and motor control. The diagram on the bottom shows an end-to-end approach to the same problem: an image is given to a deep neural network that learns its own features and executes actions directly on the actuators.}
    \label{fig:intro_end2end}
\end{figure}

\section{Robotic learning}
Machine learning introduction:
    - positioning ML (cfr https://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)
    - success applications: ML is preferred approach for MLP, speech recognition and computer vision , ... 
    - What is ML fundamentally. Definition. What does ML hopes to achieve ultimately? 
    - What is holding ML back in robotics? 
        Datasets, sample-efficient learning, weak or undefined learning signals 
        * a note on hardware debt.

Process of doing robotic laundry is visualized in Figure~\ref{fig:intro_ml_flow}.
\input{\home/chapters/01-introduction/figures/ml-flow.tex}

\section{Accelerating robotic learning}
\subsection{Datasets}
\subsection{Simulation}
\subsection{Instrumentation}
\section{From behavioral cloning to understanding task intent}
\section{Research contributions} \label{sec:intro_contributions}
\begin{itemize}
    \item Dataset with people folding clothing
    \item Unsupervised reward function
    \item Low-cost robot setup to fold cloth invivo
    \item Instrumentation
    \item Gripper for folding
\end{itemize}

\section{Thesis structure}
This thesis is structured to first provide preliminary background and a review of the relevant literature. The remainder of the thesis deals with the methodology and results iterated in the previous Section~\ref{sec:intro_contributions}. The structure is as follows:
\begin{itemize}
    \item In Chapter~\ref{ch:lit}, we
\end{itemize}


\end{document}
