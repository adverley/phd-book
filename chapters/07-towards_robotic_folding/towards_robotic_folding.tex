% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode

\providecommand{\home}{../..}
\documentclass[\home/main.tex]{subfiles}

\begin{document}

\chapter{Towards robotic manipulation of clothing }\label{ch:towards_robotic_folding}
% INSPIRATIE:
%   Billard2019
%   
\section{cfr structure literature}

Too much end2end, there is a lot of prior work exposing good tricks: use gravity to unfold, immobilize parts of the cloth, make dedicated grippers ... cfr first part of literature. 

Curricilum!  spectrum: Manual, heuristic or learned
    % https://arxiv.org/pdf/2109.11978.pdf  --> 

        %  --> locomotion met PPO. Twee trucken: simulatie massaal in parallel op GPU (IsaacGym’s PhysX engine) en heuristisch curriculum.
        %  Heuristisch curr is langzaam de helling van het terrein en trappen verhogen. De heuristiek houdt ook rekening met forgetting door af en toe een random lager level te introduceren of het algemene level terug te verlagen.

Sensing!


Multimodal learning.
Unify RL and imitation learning. p14 a survey of deep network solutiosn for learning control in roboits: from RL to imitation.

Datasets 
    Self-supervision 
        labeled cloth 
    In the wild zoals youtube
    
    

Structure:
\begin{easylist}
    & Modeling and simulation
    & Perception 
    & Control 
    & Hardware 
        && Sensors, tactile 
        && end-effectors 
\end{easylist}
The most promising research directions point toward addressing multimodal perception, integration of analytical and data-driven methods, and development and use of simulators for data generation, model evaluation, and benchmarking.

Data-driven methods from the machine learning domain have proven extremely powerful for adaptive and robust control. However, they require many examples which are expensive to generate on real, physical systems. The outlook remains that highly parametrized functions such as neural networks will keep on requiring and improving on large amounts of data \autocite{sun2017revisiting}. Hence, simulation will remain an important tool for robotic learning. As distilled in \cref{ch:sota}, there are two roads towards exploiting simulations: learning from interaction or constructing large datasets with realistic grasping examples, similar to Dex-Net \autocite{dexnet}. As of today, it appears the second road, i.e.\ generating datasets, has proven to be commercially exploitable in comparison to learning from interaction. Dex-Net for example, has been commercialized two years after its advent\footnote{https://www.ambirobotics.com/}. Realistic simulation of friction, material deformation and other physical properties will have to be researched before the soft the deformable object manipulation domain can follow along the same path as their rigid counterpart. Entry point om over simulators te praten.

==============
HARDWARE:
=============

In food, we use pneumatic gripper because they solve the grasping problem realitively easy. However, manipulation tasks are difficult with pneumatic grippers. For example, grasping a sliced potato and putting it with the chopped side in a confined space is difficult to execute with pneumatic end-effectors. Hence we need dexteours hands, with fingers , sensors, small actuartors, precision. 

Zie ook Billard2019 p4 links kolom --> vandaag zijn robotic hands stijf door motoren en links. 

Design beyond human hand: two thumbs, suction at finger tips like fish. (cfr Billard2019). 

Bimanual robot manipulation is underdeveloped \autocite{Billard2019}. Important for cloth: for example, fix the cloth against the tables while using the other hand to fold it. 


Further research toward several technologies vital for meeting and exceeding human dexterity and fine manipulation capabilities is needed .


“Tactile sensing always seems years away from widespread utility compared to vision” 
and
“Dexterous multifingered hands have not really been applied to any major application in industry, mainly because of problems of reliability, complexity and cost” 
  - Melchiorri and Kaneko in Springer Handbook of Robotics by Siciliano and Khatib


==============
DATASETS:
=============

Datasets have enabled deep learning. Datasets have enabled great successes for robotic manipulation. In the case of grasping objects, it seems Dex-Net takes the lead because it allows to completely frame the problem as a supervised learning problem leading to a more qualitative learning signal. Additionally, working in simulation has allowed them to generate $6.7$ million images which is approximately $7$ times the size of the largest data collection setup of a single institution~\autocite{Levine2016}. However, synthetic data is plagued with transferability problems which makes realistic simulations, robust algorithms and system identification crucial. 
We have good retail fashion datasets~\autocite{DeepFashion, DeepFashion2, FashionAI}, but now we need more modalities, interactions and need to find a way to make them useful for robotic manipulation tasks. 
I really like the FashionAI AttributeNet that disentangles attributes using experts, labels some data, train a network and stop training when the network is failing on some attributes. This allows scaling up data collection.
Existing robotic interaction datasets only contain vision, no touch. 
Existing robotic learning datasets are too versplinderd, no common standard, hard to consolditate. 
We need high quality and high volume datasets like the retail have, but then for robotic applications. 
DefGraspSim is a first attempt towards dexnet like data.

a very recent attempt at benchmarking deformable object manipulation is initiated by \autocite{garciacamacho2021household}. This benchmark proposes a set of common available deformable household object and provides a protocol of tasks and evaluation methods.

===================
Function approximators 
===================
An honest assessment has to be that current deep learning methods are not well suited to online learning. (sutton barto book p494)

===================
SIMULATORS 
===================
Deformable bodies require reasoning about the shape, dynamics and material properties of the object. -> this is why NN are so interesting. They can learn it.

Embed simulation structure in neural netwokr. 

MASSAAAL IN PARALLELL. GPUS are the way! Zoals SoftGym of wat was het?

interdisciplinary: medical img -> deformable object modeling: shape representation. zie comment hieronder.
    % Sun et al. used methods of particle-based smoothing as well as non-parametric belief propagation on a loopy graphical model capturing the temporal periodicity of the heart, with the objective being to estimate the current state of the object not only from the data observed at that instant but also from predictions based onpastandfutureboundaryestimates. Eventhoughwedid not find examples of this method being used in robotics, it seems a suitable candidate since it models the shape change through time implicitly and would thus allow the robot to keep track of the evolving shape of an object during manipulation. 

How far can we go? The cloth simulation of blender for example is shown to be not transferrable to the real world in recent work of \autocite{Tanaka2018}.

diff physics:
    optimize the following:
        control
        system identification  (sim2real gap overcomming)
        body 


        % (from: https://www.frontiersin.org/articles/10.3389/frobt.2020.00082/full)
        DL dynamics models 
        Deep NN models are similar to      the NN dynamics models described in section 3.2.3 but are more
        scalable; for example, they can be used to model interactions
        between multiple objects in a single scene. We call these
        methods deep learning-based dynamics models. An advantage
        of these models is that they can learn directly from sensory
        observations (e.g., images of the observed scene) with high
        accuracy by virtue of their end-to-end differentiability, unlike
        the more computationally expensive analytical dynamics models
        in section 3, which are mostly too complex to differentiate.
        However, deep learning-based models have two limitations. First,
        most methods based on differentiable dynamics models are tested
        on limited scenarios with a few interacting rigid objects (e.g.,
        balls colliding), which makes them difficult to generalize to
        more complicated behaviors of deformable objects. There are
        differentiable dynamics models that can learn more complex
        deformable object behavior, as in Mrowca et al. (2018) and Li
        et al. (2018); however, they may exhibit visually implausible
        deformations, such as the loss of shape preservation over time,
        or may not be able to deal with visual perception that includes
        partial or noisy observations of the state of objects, for instance
        due to the occlusion of a robot manipulator with an object.
        Furthermore, NN-based methods mostly work on entities of fixed
        dimensionality and do not exploit characteristics, such as the
        flexibility of splines.
        In conclusion, for the future we need algorithms that
        can deal with various challenging manipulation scenarios
        where previously unseen objects appear in a scene (e.g.,
        in contexts, such as cooking or nursing) by incrementally
        learning the shape and dynamics of a previously unseen object
        simultaneously while planning and controlling manipulation.
        To develop such methods, different approaches, such as
        integrating efficient differentiable models with physically
        accurate dynamics models, should be investigated. Also, models
        of dynamics should be adapted to work on different families of
        shape representations.
    
--------------------------
    SIM2REAL
--------------------------
Sim2Real will always remain important because solely further increasing the simulator's accuracy alone will not bridge the sim2real gap.
Useful domain randomization -> most informative, dont bruteforce the whole domain 
System identification for simulation 

--------------------------
    reward learning
--------------------------
Learning rewards is equivalent to learning which signal to give to an agent such that its personal performance on the task can increase. This constitutes two elements: personal and performance. We focus on the performance part: what is task intent being encoded in the demonstrations provided by the demonstrator? However, it might be beneficial to couple the learning process to the learning characteristics of the agent. One method to incorporate this characteristic is curriculum learning. In curriculum learning, we adapt the setting of the task to the performance level and characteristics of the learning agent.  

--------------------------
    learning in general
--------------------------

Learning is important in adapting to unseen scenarios and operating in unstructured environments. 
BUT
Do we have to learn everything?
    deconstruct end-to-end systems
    smart textile that tells whether it is folded vs letting the robot infer it by interaction 


 ----------------------------------------------------
    Human-robot collaboration
----------------------------------------------------
An aspect untouched in this research but of great importance in DOM: collaborative manipulation of deformable objects between robot and human. Examples include robot-assisted dressing \autocite{Gao2016}, assitive support \autocite{lu2017human} and bed-sheet folding \autocite{Kruse2015}.


\end{document}