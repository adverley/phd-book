% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode

\providecommand{\home}{../..}
\documentclass[\home/main.tex]{subfiles}

\begin{document}

\chapter{Towards robotic manipulation of clothing }\label{ch:towards_robotic_folding}
\section{cfr structure literature}

Too much end2end, there is a lot of prior work exposing good tricks: use gravity to unfold, immobilize parts of the cloth, make dedicated grippers ... cfr first part of literature. 

Curricilum!
Sensing!


Multimodal learning.
Unify RL and imitation learning. p14 a survey of deep network solutiosn for learning control in roboits: from RL to imitation.

Datasets 
    Self-supervision 
        labeled cloth 
    In the wild zoals youtube
    
    

Structure:
\begin{easylist}
    & Modeling and simulation
    & Perception 
    & Control 
    & Hardware 
        && Sensors, tactile 
        && end-effectors 
\end{easylist}
The most promising research directions point toward addressing multimodal perception, integration of analytical and data-driven methods, and development and use of simulators for data generation, model evaluation, and benchmarking.


Datasets have enabled deep learning. Datasets have enabled great successes for robotic manipulation. In the case of grasping objects, it seems Dex-Net takes the lead because it allows to completely frame the problem as a supervised learning problem leading to a more qualitative learning signal. Additionally, working in simulation has allowed them to generate $6.7$ million images which is approximately $7$ times the size of the largest data collection setup of a single institution~\autocite{Levine2016}. However, synthetic data is plagued with transferability problems which makes realistic simulations, robust algorithms and system identification crucial. 
We have good retail fashion datasets~\autocite{DeepFashion, DeepFashion2, FashionAI}, but now we need more modalities, interactions and need to find a way to make them useful for robotic manipulation tasks. 
\end{document}