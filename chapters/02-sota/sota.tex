% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode


% TODO: ik heb een goed idee waar het naar toe moet hoor, tis gewoon de uitvoering en flow dat moet kloppen. Ik ben van plan het eerst eens uit te werken voor een bepaald onderdeel van het literatuur hoofdstuk, te reviewen met jou en dan die stijl\flow\template toepassen voor de andere secties in dat hoofdstuk

\providecommand{\home}{../..}
\documentclass[\home/main.tex]{subfiles}

\begin{document}

\chapter{Background and related work}\label{ch:lit} 

% TODO: hallo andreas! welcome back! Herlees eerst dit en schrijf verder de structuur. No worries, de structuur vanaf "datasets for robotic learning" zit nog niet zo strak maar door te schrijven kan je itereren! Kijk ook naar de structuur van:
%           - Jan Matas zijn thesis
%           - Sergey Levine en Gabriel Urbain hun PhD 
%           - Thomas en Jannick hun thesissen
The goal of the following chapter is to provide the prelimaries and a review of relevant work in the field of robotic manipulation of deformable objects. We first discuss how \emph{standard robotic manipulation pipelines} can be used for manipulating deformable objects in Section~\ref{sec:lit_traditional}. Next, we introduce how the inherent limitations of engineered motor control architectures can be overcome by using \emph{learning-based methods} in Section~\ref{sec:lit_learning}. We break this section down into subsections introducing supervised learning, deep neural networks and reinforcement learning. This is followed by surveying their applications in recent robotic manipulation work. Given the general property that learning-based methods are data hungry, we continue this discussion by reviewing the role of \emph{large datasets} for robotic learning in Section~\ref{sec:lit_datasets}. An alternative approach to generating data is to use synthetic data. To this end, we discuss the role of \emph{simulation} and the corresponding transferrability problems in Section~\ref{sec:lit_simulation}. Critical to robotic learning of manipulation skills is some metric of task success, generally defined as reward function. The role of \emph{reward functions} for robotic learning, and deformable objects manipulation in particular, is reviewed in Section~\ref{sec:lit_reward_learning}. Finally, we discuss the idea and corresponding literature of \emph{instrumenting the process with sensors} to facilitate the learning process in the manipulation environment in Section~\ref{sec:lit_instrumentation}.

% Goedemiddag Andreas! Storm flink geweest bij de DA? Lees bovenstaande paragraaf en schrijf lekker aan sectie 1: stnadard motor control architecutres. Gebruik hiervoor sergey levine zijn phd als guideline.



\section{Manipulating deformable objects} \label{sec:lit_traditional}
% traditionele pipelines, bondig. Doel: nood aan learning approaches schetsen

Prior to the success of using deep neural networks in an end-to-end fashion, standard motor control architectures were constructed using a modular, decomposed approach. For example, the cloth folding pipeline of~\citeauthor{Doumanoglou2016} starts with a visual perception module which detects ... This visual module is then used by ...

\section{Learning approaches to robotic manipulation} \label{sec:lit_learning}
% structuur: SL basics introduceren en dan toegepaste papers? Of eerst de ganse "knowledge background stack" en dan de standaard literatuur? best optie 1.

\subsection{Supervised learning} \label{subsec:lit_sl}
\subsection{Deep neural networks} \label{subsec:lit_dnn}
\subsection{Reinforcement learning} \label{subsec:lit_rl}

Reinforcement Learning is an eminent approach for learning control policies with no user intervention. A complete review of RL is outside the scope of this thesis, the reader is referred to the standard textbook of~\citeauthor{SuttonAndBarto}. 

\section{Datasets for robotic learning} \label{sec:lit_datasets}
\section{Simulation environments to accelerate learning} \label{sec:lit_simulation}
\subsection{Cloth simulation methods} \label{subsec:lit_cloth_sim}
\subsection{Transferring simulation results to the real world}  \label{sec:lit_sim2real}
\section{Reward learning}  \label{sec:lit_reward_learning}
\section{State perception through instrumentation} \label{sec:lit_instrumentation}

\end{document}