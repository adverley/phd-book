% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode


% TODO: ik heb een goed idee waar het naar toe moet hoor, tis gewoon de uitvoering en flow dat moet kloppen. Ik ben van plan het eerst eens uit te werken voor een bepaald onderdeel van het literatuur hoofdstuk, te reviewen met jou en dan die stijl\flow\template toepassen voor de andere secties in dat hoofdstuk

\providecommand{\home}{../..}
\documentclass[\home/main.tex]{subfiles}

\begin{document}

\chapter{Background and review of related work} \label{ch:lit}

The goal of the following chapter is to provide the preliminaries and a review of relevant work in the field of robotic manipulation of deformable objects. To provide some historical context, we first discuss how \emph{standard robotic manipulation pipelines} can be used for manipulating deformable objects in Section~\ref{sec:lit_traditional}. Next, in Section~\ref{sec:lit_learning} we introduce how the inherent limitations of engineered motor control architectures can be overcome by using \emph{learning-based methods}. We break this section down into subsections introducing supervised learning, deep neural networks and reinforcement learning. This is followed by surveying their applications in recent robotic manipulation work. Given the general property that learning-based methods are data-hungry, we continue this discussion by reviewing the role of \emph{large datasets} for robotic learning in Section~\ref{sec:lit_datasets}. An alternative approach to generating data is to use synthetic data. To this end, we discuss the role of \emph{simulation} and the corresponding transferability problems in Section~\ref{sec:lit_simulation}. Critical to robotic learning of manipulation skills is some metric of task success, generally labelled as reward function. The role and methods to obtain \emph{reward functions} for robotic learning, and deformable objects manipulation in particular, is reviewed in Section~\ref{sec:lit_reward_learning}. Finally, we discuss the idea and corresponding literature of \emph{instrumenting the process with sensors} to facilitate the learning process in the manipulation environment in Section~\ref{sec:lit_instrumentation}.

\input{\home/chapters/02-sota/a-manipulating-deform-objects}

\section{Learning-based approaches to robotic manipulation} \label{sec:lit_learning}
% Houvasten: Matthias, Jim, Gabriel 

Machine learning, a domain of artificial intelligence, is the study of algorithms that give computers the ability to learn from and make predictions based on data. Learning provides a viable alternative for robotics as it gives a way to deal with the inherent systematic as well as random errors in robotic systems and variability in unstructured environments. This is because in learning, you optimize for the grasping task, which implicitly adapts the behaviour to imperfections in the system such as inaccurate sensor readings.

In this section, we provide a short review on the fundamentals of relevant machine learning techniques. We aim to provide background material on \acrfull{DRL}, i.e. the method used in this thesis. To do this, we introduce supervised learning methods (\cref{subsec:lit_sl}), deep neural networks (\cref{subsec:lit_dnn}) and reinforcement learning (\cref{subsec:lit_rl}). We discuss their relevant applications in robotic manipulation with a focus on the manipulation of deformable objects. This section aims to provide an understanding on these domains, based on required essentials. For a comprehensive view on the machine learning field, the reader is referred to~\autocite{Friedman2001} and~\autocite{Bishop2006}.

\subsection{Supervised learning} \label{subsec:lit_sl}

% ALE HUP
%  Je zit hier wat vast he. Kijk per stuk naar standaardlessen (Coursera ML, stanford deep learning course, sergey levine DRL course) en breng hun structuur over naar hier. Je kan hoofdstukken mappen naar subsecties en zelfs paragrafen. Filter het meest relevante eruit. 

%  Overweeg om even deze structuur overboord te gooien en te herdenken!
% Overweeg eerst nog is te kijken hoe volgende mensen hun ML en SL opbouwen:
% 		Gabriel zijn boek
% 		ML course andrew NG
% 		Matthias zijn boek
% 		Jim zijn boek 
% 		DL book ch5
% Begin maar direct zeer formeel. Teken schets van structuur uit en vul gewoon in. Nadien terugkomen voor meer context enzo toe te voegen.


Supervised learning is a machine learning paradigm where there is a set of \textit{input} variables that exert influence over other \textit{output} variables. For example \dots. More formally, we can denote the input data as a set X consisting of vector x in X. In the machine learning domain, this set of predictor variables is often called \textit{features}. The set Y contains the output variables y in Y. Concatening tuples of (xi, yi) leads to a dataset which can be used for learning. 

STRUCTUUR:
	Definition: dataset, models , OF optimization, grad descent, splits 
	Application in robotic learning:
		perception modules of modular pipelines
		imitation learning: survey argall 
		direct learning: dexnet, google levine paper 
		(! focus on cloth applications)

Supervised learning is an important paradigm for robotic learning because labelled data provides a clear learning signal as opposed to reinforcement learning(\cref{subsec:lit_rl}) where the learning signal often does not optimize for direct task performance. 

The learning happens in the 'model'. Can be many things: decision trees, linear models, ANNs. 
Central idea is to change parameters of the model such that the outputs of the model matches the outputs of dataset, given the inputs. 
grad descent. 


\subsection{Unsupervised learning}
Definition
Relevance:
	 dimensionality reduction: PCA, T-sne, UMAP 
	 clustering 
Application in learning (very short): visualization of embeddings, separation of cloth, ... 


\subsection{Deep neural networks} \label{subsec:lit_dnn}
Structure: 
	- Motivation: representation matters
	- ANN, MLP basics: neurons, activations, nonlinearities, layers, feedforward, 
	- optimization: backpropagation 
	- CNNS
	- Increasingly abstract representation through deep layers 
	- Applications in robotics:
		perceptual module in pipelines
		dexnet, google levine paper
		cfr review deep learning in robotics 

Comprehensive review on~\acrshortpl{DNN}, see the textbook of~\textcite{Goodfellow2016}.

\subsection{Reinforcement learning} \label{subsec:lit_rl}
contrast to SL 
why relevant for robotics
MDP formalisatie
from bellman equation to q-learning 
RL loop and elements: state representation, reward function. 
RL architectures and categorization: value based, policy methods, actor critics 
Applications in robotic manipulation and cloth 

Reinforcement Learning is an eminent approach for learning control policies with no user intervention. A complete review of RL is outside the scope of this thesis. Therefore, we refer the reader to the standard textbook of~\textcite{Sutton2018}.

\section{Datasets for robotic learning} \label{sec:lit_datasets}
Motivatie:
	Link met SL
	Link met RL, offline RL 

Kan simulatie of echte data zijn. 

Relevante werken:
	DexNet, 

\section{Simulation environments to accelerate learning} \label{sec:lit_simulation}

Motivatie voor simulatie: dure, trage robot tijd 
Componenten: physics engine, robot simulatie, link naar fysische platform.

\subsection{Cloth simulation methods} \label{subsec:lit_cloth_sim}
%Zie ook "Robotic manipulation and sensing of deformable objects in domestic and industrial applications: a survey" p4 voor overzicht om te introduceren maar focus op particle based methods.

Wat maakt cloth simulatie moeilijk. 
Aanpakken tot cloth simulatie (kort de categorisatie)
Particle based method. 
Integrators. 
Ander werk dat gebruik maakt van cloth simulatie voor robotic maniulation.

\subsection{Transferring simulation results to the real world}  \label{sec:lit_sim2real}
sim2real problem uitleggen.
Verschillende aanpakken uitleggen: Meta learning, simulatoin randomization, system identifitcation, domain adaptation
literatuur bespreken. 

\section{Reward learning}  \label{sec:lit_reward_learning}
General introduction 
Motivatie: Reward hacking, impossible to capture all ingredients
Literatuur: 
	IRL 
	Reward learning 

\section{State perception through instrumentation} \label{sec:lit_instrumentation}
Motivatie.
Definitie.

literatuur:


\end{document}