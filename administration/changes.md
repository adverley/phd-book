Implemented changes:
General:
- Fix typos across chapters during reread.
- Fixed all typos reported by Prof. Derammelaere
- Fixed all typos, historical accurate references, correction and nuances as reported by Prof. Belpaeme
- Fixed the list of typos reported by Prof. Simoens

CH1
- Updated contributions in ch1: our paper on learning reward functions is published in Springer APIN.

CH3
- Fixed Verlet integration equation as reported by Prof. Simoens
- ch3: fully specified how the size of action and state space is calculated
- Fixed wrong colour references in Chapter 3, Figure 3.5
- Elaborated on how the experiments were conducted (separate network per subtask, weights, etc)
- appendix A now includes an additional table containing additional training parameters: weights of reward function (and how it was tuned), learning rate, neural network architecture, 

CH6
- ch6: better explain how the reward function is extracted from the aligned embeddings (i.e. explain the ambiguous phrase "cost of best fit")
- explicitly labelled the squared l2 norm in triplet loss formula 



